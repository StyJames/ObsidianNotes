# Java
1. 聊聊Java的NIO
	1. NIO是非阻塞IO，他被设计成高效并且面向块的IO方式，是针对原来BIO即阻塞式IO的一种更高效的设计。NIO提供了的Buffer来作为缓冲区，抽象出来一个Selector来作为网络、文件交互的总线，或者叫多路复用器。并将网络套间字、文件等原来的Socket抽象为一个个的双向全双工Channel或者叫通道。
	2. 交互的大体过程，首先按需选择网络、文件等的channel抽象实现，进行初始化，并注册到对应的Selector上,如果该channel有新的文件或者链接，就会设置selectKey状态为就绪。同时selector会对已经注册并就绪的channel进行轮询，然后通过Buffer来发送数据流。
	3. 后续JDK7，针对NIO提供了异步的设计
2. 谈谈JVM
	1. JVM是Java一次书写到处运行的基础，它帮助开发者屏蔽了底层硬件专注于代码开发。并且提供了GC机制，来帮助开发者进行内存回收，也使得Java更易于作为服务器长时间稳定的运行。
	2. JVM在内存中开辟了一套专有的数据空间。分为堆,方法区，虚拟机栈，本地方法栈，PC计数器。其中GC的主要对象是堆。
		1. 堆又分为新生代和老年代，所有的对象和数组都在这里进行初始化
		2. 方法区有常量池缓存数据，加载的类信息以及JIT优化的编译后代码等
		3. 虚拟机栈存储的是每一次方法调用的栈帧，栈帧内是方法内基本信息、变量表等
		4. 本地方法栈存储的是Java调用偏底层的native方法一般是C、C++实现，在Java中一条方法调用
		5. PC计数器存放的是当前线程正在运行方法的JVM地址
	3. JVM整体包含类加载系统、执行引擎、运行时数据区（其中运行时数据区最多考量）
3. 类加载机制

# MySQL

1. 谈谈MySQL的隔离级别，四种均可选，默认是读已提交。事务的隔离机制的实现是基于锁和多版本并发控制（MVCC），通过保存旧版数据来支持一致性读和回滚等策略。
	1. 读未提交，没有任何锁策略，可以读取未提交事务的更新，即出现脏读
	2. 读已提交-MySQL默认，仅能读到其他事务已经提交的更新，解决脏读，即一个事务读取了另一个事务未提交的数据。
	3. 可重复读-Oracle默认，一个事务连续两次读到的同一数据是一致的，可解决不可重复读，即一个事务前后针对同一个数据读到不同的值。
	4. 串行化，修改数据时对表增加排它锁，只能读不能写，所有事务串行，可解决幻读
2. 脏读幻读不可重复度的相关描述，不可重复读侧重于修改，幻读侧重于新增或删除（多了或少量行），脏读是一个事务回滚影响另外一个事务。
	1. 脏读，事务 A 读取了事务 B 更新的数据，然后 B 回滚操作，那么 A 读取到的数据是脏数据
	2. 不可重复读，事务 A 多次读取同一数据，事务 B 在事务 A 多次读取的过程中，对数据作了更新并提交，导致事务 A 多次读取同一数据时，结果 不一致。
	3. 幻读，系统管理员 A 将数据库中所有学生的成绩从具体分数改为 ABCDE 等级，但是系统管理员 B 就在这个时候插入了一条具体分数的记录，当系统管理员 A 改结束后发现还有一条记录没有改过来，就好像发生了幻觉一样，这就叫幻读。
3. MySQL事务的实现，基于`redolog-重做日志`和`undolog-回滚日志`实现的。每提交一个事务必须先将该事务的所有日志写入到重做日志文件进行持久化，数据库就可以通过重做日志来保证事务的原子性和持久性。每当有修改事务时，还会产生 undo log，如果需要回滚，则根据 undo log 的反向语句进行逻辑操作，比如 insert 一条记录就 delete 一条记录。undolog 主要实现数据库的一致性。
4. MySQL的日志系统
	1. 事务日志，来保证事务和多版本并发控制
	2. 二进制日志，用于备份
	3. 查询日志，用于记录
	4. 慢查询日志，用于记录，保留SQL待优化
	5. 错误日志，用于记录
5. redolog和undolog是MySQL的事务日志，处于innoDB的引擎层。
	1. redolog记录了已提交的事务对数据页做了哪些修改
	2. redolog的结构分为两部分，redolog buffer ，内存中的日志缓冲，redolog file,磁盘中的日志文件。操作流程就是，每执行一条DML语句，先记录到日志缓冲，后续某个节点会统一刷到日志文件中。![](v2-e69b02f799b265a1f00e45e2ee8e040c_1440w.webp)
	3. undolog,保存了每一条执行的DML语句的反向SQL，保证了事务可以回滚到某一个版本
6. MySQL的 binlog 是什么，它是记录所有数据库表结构变更（例如 CREATE、ALTER TABLE）以及表数据修改（INSERT、UPDATE、DELETE）的二进制日志。处于MySQL的Server层，即使用任何的引擎都会存在binlog
	1. binlog的使用场景有如下两个，一个是主从复制，一个是数据恢复
	2. 主从复制就是，在Master端开启binlog，并同步发送给各个slave端，slave端重放binlog，慢慢同步SQL，从而达到主从数据一致
	3. 数据恢复就是指通过mysqlbinlog工具来进行数据的恢复
	4. binlog刷盘，对于innoDB的引擎，在事务提交的时候，会记录信息到binlog，此时数据还在内存。MySQL通过 sync_binlog变量的配置来控制刷盘时机。
		1. `sync_binlog = 0`代表由系统控制刷盘时机
		2. `sync_binlog = 1`代表一次事务完成，就刷一次盘
		3. `sync_binlog = N`代表N次事务提交之后再刷盘
	5. binlog的日志格式
		1. STATMENT，基于SQL语句，每一条改动数据的SQL都会被记录进binlog
		2. ROW，基于数据行变更的记录
		3. MIXED，基于如上两种模式的同时混合复制，在一般场景下采用STATMENT格式，在STATMENT格式无法保存的场景下，使用ROW模式进行数据的保存
7. MySQL的MVCC
	1. 多版本并发控制，通过保存数据在某一时间的快照实现的。根据事务开启的时间不一样，每个事务对同一张表，同一时刻看到的数据可能不同。
	2. 针对于innoDB引擎来说，为了实现MVCC，设计了rowid、事务ID、回滚指针。
	3. 大致处理流程，每一行数据都存在一个隐藏的回滚指针指向，用于指向该行修改前的最后一个历史版本，历史版本存放于undolog中。如果需要执行更新操作，会将原纪录放入undo log中，并通过隐藏的回滚指针指向undolog中的原纪录。此时其他事务查询数据就是查询该undolog中的原记录。读不加锁，读写不冲突。

# 后端系统的三高设计
## 高并发
大量用户使用带来的一些高并发请求，解决方案是进行水平伸缩，即不再考虑进行单机的硬件性能升级，而是引入更多的机器进行一个分布式集群搭建，然后对外统一的提供服务，以此来提升系统的处理能力。
单机->分布式->负载均衡->数据库读写分离，架构慢慢演化

## 高性能
响应时间、并发数、吞吐量、系统的性能计数器
1. 响应时间指从发送请求到获取响应结果的完整时间，反应系统快慢
2. 并发数指系统同时处理的并发数，反应系统负载
3. 吞吐量指单位时间内，系统处理请求的数量，体现系统处理能力
4. 一些衡量指标如HTTP请求数HPS、每秒查询数QPS、每秒事务数TPS、系统负载、CPU、内存使用、磁盘与IO等
## 高可用
在各种外界环境的影响以及对应内部某些软硬件环节出问题的情形下，应用都要是可用的，用户都能够正常访问系统，完成业务处理，衡量指标是满足全年可用时间的几个9

# 项目开发点梳理

理财子风控自研，toB项目：
核心点，从jdk6+weblogic+Oracle的前后端未分离项目升级到微服务化的jdk8+Springboot+MySQL的前后端项目。
大致架构如下：
1. 后端底层数据分两部分，一部分来自rocketMQ下发的上游交易订单数据，一部分来自于大数据ETL推送的债券、基金、存款等的行情数据，这部分数据需要定时任务处理之后再刷到实际业务表中。一个微服务负责专门做MQ的收发，后续拓展到更多上游系统的行情数据接入以及下游的数据输出，一个微服务负责专门的定时任务调度，行情数据的入库
	1. 其中针对这个交易订单的MQ，出现过重复消费和不按顺序消费的情况，所以这里做了几个优化点，首先是针对交易流水设置了Redis的分布式锁setnx，并且根据观察到的平均处理时间设置了更长一点的锁超时时间
	2. 不按顺序消费的问题，这边是增加了一个上游交易状态变化修改会记录的一个时间戳，业务处理的时候会首先去对比数据库的时间戳，往前的时间戳数据直接抛弃不处理，并返回消费成功
	3. 保证幂等性的处理，我们这边后续有接入其他一些时效不敏感的基本信息，交易信息是根据唯一交易流水加时间戳进行的业务场景下的幂等性，基本信息会根据数据量或者数据特性来确定是否需要幂等，或者直接通过业务主键进行更新
	4. 第三方推送的大量行情数据入库，一般采用定时任务多线程批量入库的方式。并且因为切换了MySQL，此处在Java代码中更多使用线程池处理+countDownLanch，几百条小批量在子线程启动事务或者业务简单不启用事务来处理数据的更新和插入（防止间隙锁导致死锁）
	5. 定时数据清理采用专门的定时任务和线程池来处理，防止出现线程等待导致数据异常
2. 处于中间层有一个微服务，专门负责和前端进行接口交互，负责具体的路由和页面接口的业务实现，并通过feign调用其他微服务对应模块进行数据响应
	1. 此处页面展示有一些前端菜单、下拉框等是直接使用的JVM缓存，guava/ehcache，存储了大量不变数据，在分布式场景下也可以直接使用
	2. 但是已经加工的行情数据是直接用Hash结构保存在Redis中的，随时变更，需要同步更新。否则是MQ刷到之后同步更新到Redis
3. 实际做交易风控，或者叫持仓规则检查（查询持仓数据的范围、选择规则范围、拼接复杂SQL、运行复杂SQL、保存结果并统一格式输出宽表）的微服务是单独拆分出来。根据前面提到的已加工数据和前端交互选中的持仓账户和规则进行具体的返回
	1. 为了分散计算压力存在标记为0-9一共10张temp表存储每次计算的实时持仓数据，通过checkId进行hash然后取模散列到具体的表
	2. 为了保证高性能，此处在后端开辟专门的线程池处理数据计算和SQL的一些运算。同时在MySQL达到性能瓶颈之后，引入了TiDB进行双写，来替代MySQL在日间实时交易时候快速返回风控结果。5并发可以保证1S左右返回宽表数据

贷后资金系统，自研，toC端
纯后端系统，主要负责交易流水的拆分合并、第三方资金方接入、还款计划更新、交易对账、渠道费用计算等。
大致架构：没有微服务化的Spring+weblogic+oracle整体架构，按照网络不同划分了三个组件，生产部署是采用了虚拟机的镜像集群部署。
主要设计流程是从交易流水表取数据，
